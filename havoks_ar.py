# -*- coding: utf-8 -*-
"""Havoks_AR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fIpkdRMzCsS-tIJlwVWBth16Hl9EG3fu
"""

!pip install torch torchvision torchaudio diffusers transformers accelerate
!pip install opencv-python numpy matplotlib
!pip install trimesh pyrender scikit-image

import os
import zipfile
import torch
import numpy as np
import cv2
import matplotlib.pyplot as plt
from PIL import Image
from diffusers import StableDiffusionPipeline
from transformers import ViTModel, ViTFeatureExtractor
from skimage.metrics import structural_similarity as ssim
from google.colab import drive

drive.mount('/content/drive')

dataset_folder_path = "/content/drive/MyDrive/dataSet"
zip_path = "/content/drive/MyDrive/dataset.zip"
extract_path = dataset_folder_path

if os.path.exists(zip_path):
    extract_path = "/content/dataset"
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_path)
    print("✅ Dataset extracted successfully!")
else:
    print(f"✅ Using dataset folder: {extract_path}")

def load_and_preprocess_images(data_path, img_size=(512, 512)):
    images = []
    if not os.path.exists(data_path):
        raise ValueError(f"❌ Dataset folder {data_path} does not exist!")

    image_files = [os.path.join(dp, f) for dp, dn, fn in os.walk(data_path) for f in fn if f.endswith(('.png', '.jpg', '.jpeg'))]

    if len(image_files) == 0:
        raise ValueError("❌ Dataset folder is empty! Upload images.")

    print(f"✅ Found {len(image_files)} images in dataset!")

    for img_path in image_files:
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        if img is not None:
            img = cv2.resize(img, img_size)
            img = img / 255.0
            images.append(img)

    return np.array(images)

dataset = load_and_preprocess_images(extract_path)

def show_sample_images(images, num=5):
    num = min(num, len(images))
    fig, axes = plt.subplots(1, num, figsize=(15, 5))
    for i in range(num):
        axes[i].imshow(images[i], cmap='gray')
        axes[i].axis('off')
    plt.show()

show_sample_images(dataset)

device = 'cuda' if torch.cuda.is_available() else 'cpu'
feature_extractor = ViTFeatureExtractor.from_pretrained("google/vit-base-patch16-224-in21k")
vit_model = ViTModel.from_pretrained("google/vit-base-patch16-224-in21k").to(device)

def extract_features(image):
    image = Image.fromarray((image * 255).astype(np.uint8))
    inputs = feature_extractor(images=image, return_tensors="pt").to(device)
    with torch.no_grad():
        outputs = vit_model(**inputs)
    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()

pipeline = StableDiffusionPipeline.from_pretrained("stabilityai/stable-diffusion-2").to(device)

def generate_architectural_diagram(prompt):
    image = pipeline(prompt=prompt).images[0]
    image.show()
    return image

prompt = "A detailed modern house floor plan with multiple rooms and accurate proportions."
generated_image = generate_architectural_diagram(prompt)

generated_image.save("generated_blueprint.png")
print("✅ Generated blueprint saved!")

from IPython.display import display

generated_image.save("generated_blueprint.png")
display(generated_image)
print("Generated blueprint displayed!")

